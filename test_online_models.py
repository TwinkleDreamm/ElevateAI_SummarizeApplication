#!/usr/bin/env python3
"""
Test online models performance vs local models.
"""

import time
import os
import sys
from pathlib import Path

def test_embedding_performance():
    """Test embedding generation performance."""
    print("ğŸ§ª Testing Embedding Performance")
    print("=" * 50)
    
    try:
        from src.database.embedding_generator import EmbeddingGenerator
        
        # Test online embeddings (OpenAI)
        if os.getenv('OPENAI_API_KEY'):
            print("\nğŸŒ Testing OpenAI Embeddings (Online):")
            start_time = time.time()
            
            online_config = {'use_openai': True}
            online_generator = EmbeddingGenerator(online_config)
            
            test_text = "This is a test sentence for embedding generation."
            embedding = online_generator.generate_embedding(test_text)
            
            online_time = time.time() - start_time
            print(f"   âœ… Time: {online_time:.2f}s")
            print(f"   âœ… Dimension: {len(embedding)}")
            print(f"   âœ… No local storage needed")
        else:
            print("\nâš ï¸ OpenAI API key not configured - skipping online test")
        
        # Test local embeddings (if available)
        try:
            print("\nğŸ’¾ Testing Local Sentence Transformers:")
            start_time = time.time()
            
            local_config = {'use_openai': False}
            local_generator = EmbeddingGenerator(local_config)
            
            embedding = local_generator.generate_embedding(test_text)
            
            local_time = time.time() - start_time
            print(f"   âœ… Time: {local_time:.2f}s")
            print(f"   âœ… Dimension: {len(embedding)}")
            print(f"   âš ï¸ Model stored locally (~90MB)")
            
        except Exception as e:
            print(f"   âŒ Local embeddings failed: {e}")
            
    except Exception as e:
        print(f"âŒ Embedding test failed: {e}")

def test_speech_to_text_performance():
    """Test speech-to-text performance."""
    print("\nğŸ§ª Testing Speech-to-Text Performance")
    print("=" * 50)
    
    try:
        from src.core.speech_to_text import SpeechToTextProcessor
        
        # Create a dummy audio file path for testing
        dummy_audio = Path("test_audio.wav")
        
        if os.getenv('OPENAI_API_KEY'):
            print("\nğŸŒ OpenAI Whisper API (Online):")
            print("   âœ… No local model download needed")
            print("   âœ… Always latest model version")
            print("   âœ… Faster startup time")
            print("   âš ï¸ Requires internet connection")
        else:
            print("\nâš ï¸ OpenAI API key not configured")
        
        print("\nğŸ’¾ Local Whisper Model:")
        print("   âš ï¸ Downloads ~244MB model on first use")
        print("   âš ï¸ Slower startup time")
        print("   âœ… Works offline")
        print("   âš ï¸ Uses local storage and RAM")
            
    except Exception as e:
        print(f"âŒ Speech-to-text test failed: {e}")

def test_nlp_performance():
    """Test NLP models performance."""
    print("\nğŸ§ª Testing NLP Models Performance")
    print("=" * 50)
    
    try:
        from src.analysis.text_analyzer import TextAnalyzer
        
        print("\nğŸš€ Lightweight spaCy Models (Current):")
        analyzer = TextAnalyzer()
        print("   âœ… No downloads needed")
        print("   âœ… Fast startup")
        print("   âœ… Basic functionality")
        print("   âš ï¸ Limited NLP features")
        
        print("\nğŸ’¾ Full spaCy Models (Optional):")
        print("   âš ï¸ Downloads ~50MB per language")
        print("   âš ï¸ Slower startup")
        print("   âœ… Advanced NLP features")
        print("   âš ï¸ Uses more RAM")
            
    except Exception as e:
        print(f"âŒ NLP test failed: {e}")

def show_storage_comparison():
    """Show storage usage comparison."""
    print("\nğŸ’¾ Storage Usage Comparison")
    print("=" * 50)
    
    print("\nğŸ“Š LOCAL MODELS:")
    print("   â€¢ Sentence Transformers: ~90MB")
    print("   â€¢ Whisper (small): ~244MB")
    print("   â€¢ spaCy models: ~50MB each")
    print("   â€¢ Cross-encoder: ~90MB")
    print("   â€¢ Total: ~500MB+")
    
    print("\nğŸŒ ONLINE MODELS:")
    print("   â€¢ OpenAI Embeddings: 0MB (API)")
    print("   â€¢ OpenAI Whisper: 0MB (API)")
    print("   â€¢ Lightweight NLP: ~5MB")
    print("   â€¢ Total: ~5MB")
    
    print("\nğŸ¯ BENEFITS OF ONLINE MODELS:")
    print("   âœ… 100x less storage usage")
    print("   âœ… Faster startup time")
    print("   âœ… Always latest model versions")
    print("   âœ… No model management needed")
    print("   âœ… Better performance on most tasks")
    print("   âš ï¸ Requires API keys and internet")

def main():
    """Main test function."""
    print("ğŸš€ ElevateAI Online Models Performance Test")
    print("=" * 60)
    
    # Test individual components
    test_embedding_performance()
    test_speech_to_text_performance()
    test_nlp_performance()
    show_storage_comparison()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ RECOMMENDATION:")
    print("Configure OpenAI API key for optimal performance!")
    print("Add to .env file:")
    print("   OPENAI_API_KEY=your_api_key_here")
    print("=" * 60)

if __name__ == "__main__":
    main()
